{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link based ranking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Exercise 1: Page rank  (Eigen-vector method)\n",
    "\n",
    "In the first exercise, we implement the Page Rank algorithm using Eigen vector method.\n",
    "\n",
    "\n",
    "### Goal:\n",
    "1. Implementing Page rank with Eigen-vector method.\n",
    "2. Testing the implemented method on a small Web with three pages (with four different link structures).\n",
    "\n",
    "### What you are learning in this exercise:\n",
    "1. Analyzing the output of PageRank for different link structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminaries:** If you want to normalize a vector to L1-norm or L2-norm, you can use `numpy` library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-norm of [1 2 3] is [0.16666667 0.33333333 0.5       ]\n",
      "L2-norm of [1 2 3] is [0.26726124 0.53452248 0.80178373]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "\n",
    "pr = np.array([1,2,3])\n",
    "print(\"L1-norm of {0} is {1}\".format(pr, pr / np.linalg.norm(pr,1)))\n",
    "print(\"L2-norm of {0} is {1}\".format(pr, pr / np.linalg.norm(pr,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links structure\n",
    "Consider a tiny Web with three pages A, B and C with no inlinks, and with initial PageRank = 1. Initially, none of the pages link to any other pages and none link to them. \n",
    "Run your algorithm for the following cases, and calculate the PageRank for\n",
    "each case:\n",
    "\n",
    "1. Link page A to page B.\n",
    "2. Link all pages to each other.\n",
    "3. Link page A to both B and C, and link pages B and C to A.\n",
    "4. Use the previous links and add a link from page C to page B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "Please note that for this section, we are using the theoretical PageRank computation (without source of rank). See the slide \"Transition Matrix for Random Walker\" in the lecture notes. Columns of link matrix are from-vertex, rows of link matrix are to-vertex. We take the eigenvector with the largest eigenvalue.\n",
    "We only care about final ranking of the probability vector. You can choose the normalization (or not) of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to compute R form L \n",
    "def computeR(L): \n",
    "    R = np.zeros(L.shape)\n",
    "    _, cols = L.shape \n",
    "    for col in range(cols): \n",
    "        R[:,col] = L[:,col].ravel() / np.sum(L[:,col])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your code here\n",
    "def pagerank_eigen(L, R=None):\n",
    "    if R is None: # We might want to compute R outside this function to avoid recomputing large matrix\n",
    "        # Construct transition probability matrix from L\n",
    "        R = computeR(L)\n",
    "    # Compute eigen-vectors and eigen-values of R\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(R)\n",
    "    # Take the eigen-vector with maximum eigven-value\n",
    "    p = np.absolute(eigenvectors[:,np.argmax(np.absolute(eigenvalues))])\n",
    "    return (R,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((4,5))\n",
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=[[0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]]\n",
      "R=[[0.  0.5 0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "p=[0.57735027 0.57735027 0.57735027]\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample case, e.g.\n",
    "L = np.matrix([\n",
    "    [0,1,1], \n",
    "    [1,0,1], \n",
    "    [1,1,0]\n",
    "])\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={0}\\nR={1}\\np={2}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Exercise 2: Page rank  (Iterative method)\n",
    "\n",
    "In the second exercise, we implement the Page Rank algorithm with an iterative approach.\n",
    "\n",
    "\n",
    "### Goal:\n",
    "1. Implementing Page rank with the iterative method.\n",
    "2. Reading the `ca-GrQc.txt` dataset and constructing its link matrix\n",
    "3. Testing the implemented algorithm on the constructed link matrix\n",
    "4. comparing the run-time of iterative method and eigen-vector method.\n",
    "\n",
    "### What you are learning in this exercise:\n",
    "1. Benefits of the iterative approach over eigen-vector method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigen-vector method has some numerical issues (when computing eigen-vector) and not scalable with large datasets.\n",
    "\n",
    "We will apply the iterative method in the slide \"Practical Computation of PageRank\" of the lecture.\n",
    "\n",
    "Dataset for practice: https://snap.stanford.edu/data/ca-GrQc.html. It is available within the same paths of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_iterative(L, R=None):\n",
    "    if R is None:  # We might want to compute R outside this function to avoid recomputing large matrix\n",
    "        R = np.multiply(L, 1 / np.sum(L,axis=0))\n",
    "    N = L.shape[0]\n",
    "    e = np.ones(shape=(N,1))\n",
    "    q = 0.9\n",
    "\n",
    "    p = e\n",
    "    delta = 1\n",
    "    epsilon = 0.001\n",
    "    i = 0\n",
    "    while delta > epsilon:\n",
    "        p_prev = p\n",
    "        p = q * np.matmul(R,p)\n",
    "        p = p + (1-q) / N * e \n",
    "        delta = np.linalg.norm(p - p_prev,1) # we use the one norm on slide 17\n",
    "        i += 1\n",
    "\n",
    "    print(\"Converged after {0} iterations. Ranking vector: p={1}\".format(i, p[:,0]))\n",
    "    return R,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct link matrix from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct link matrix from file\n",
    "n_nodes = 0 # number of nodes in the dataset\n",
    "nodes_idx = dict() #Since the nodeIDs are not from 0 to N we need to build an index of nodes\n",
    "nodes = [] #We also want to store nodeIDs to return the result of ranking vector\n",
    "\n",
    "with open(\"ca-GrQc.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines: # find number of nodes first to initiallize an adjacency matrix\n",
    "    words = line.split()\n",
    "    if words[0] == '#' and words[1] == \"Nodes:\": \n",
    "        n_nodes = (int(words[2]))\n",
    "        adj = np.zeros((int(words[2]),int(words[2])))\n",
    "        break\n",
    "\n",
    "next_index = 0 # require separate indices because the node IDs are not subsequent\n",
    "\n",
    "node_to_adj_index = {}\n",
    "\n",
    "for line in lines: # populate the adjacency matrix\n",
    "    words = line.split()\n",
    "    if words[0] != '#': \n",
    "\n",
    "        if int(words[0]) in node_to_adj_index: \n",
    "            ii = node_to_adj_index[int(words[0])]\n",
    "        else: \n",
    "            nodes.append(int(words[0]))\n",
    "            ii = next_index\n",
    "            next_index += 1 \n",
    "            node_to_adj_index[int(words[0])] = ii\n",
    "\n",
    "        if int(words[1]) in node_to_adj_index: \n",
    "            jj = node_to_adj_index[int(words[1])]\n",
    "        else: \n",
    "            nodes.append(int(words[1]))\n",
    "            jj = next_index\n",
    "            next_index += 1 \n",
    "            node_to_adj_index[int(words[1])] = jj\n",
    "\n",
    "        adj[ii, jj] = 1 \n",
    "        adj[jj, ii] = 1\n",
    "    \n",
    "nodes_idx = node_to_adj_index\n",
    "L = adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the run-time of eigen-vector and iterative methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will see that eigen-vector method is slow and has some numerical issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we pre-compute the R matrix and pass it as argument to Page rank algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.2   0.5   ... 0.    0.    0.   ]\n",
      " [0.125 0.    0.    ... 0.    0.    0.   ]\n",
      " [0.125 0.    0.    ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.    0.    0.    ... 0.    0.5   0.5  ]\n",
      " [0.    0.    0.    ... 0.5   0.    0.5  ]\n",
      " [0.    0.    0.    ... 0.5   0.5   0.   ]]\n"
     ]
    }
   ],
   "source": [
    "R = np.multiply(L, 1 / np.sum(L,axis=0))  # note that this doesn't handle zero columns\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 46.3155038356781 seconds ---\n",
      "Ranking vector: p=[5.44214300e-18 8.67126284e-19 7.12110082e-18 ... 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# Run PageRank\n",
    "R,p = pagerank_eigen(L, R)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Ranking vector: p={0}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 128 iterations. Ranking vector: p=[2.91315639e-04 1.88382754e-04 8.39741651e-05 ... 1.92156702e-04\n",
      " 1.92156702e-04 1.92156702e-04]\n",
      "--- 0.5478830337524414 seconds ---\n",
      "Ranking vector: p=[2.91315639e-04 1.88382754e-04 8.39741651e-05 ... 1.92156702e-04\n",
      " 1.92156702e-04 1.92156702e-04]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Run PageRank\n",
    "R, p = pagerank_iterative(L, R)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Ranking vector: p={0}\".format(p[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's extract top-k nodes from the ranking vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 nodes: [14265 13801 13929]\n",
      "Their scores: [0.00144951 0.00141553 0.00138011]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(p[:,0])\n",
    "k = 3\n",
    "k_idx = ind = arr.argsort()[-k:][::-1] # index of top-k nodes\n",
    "print(\"Top-{0} nodes: {1}\".format(k, np.array(nodes)[k_idx]))\n",
    "print(\"Their scores: {0}\".format(arr[k_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Exercise 3: Ranking Methodology  (Hard)\n",
    "This exercise is theoretical and you don't need to write code for it:\n",
    "\n",
    "1. Give a directed graph, as small as possible, satisfying all the properties mentioned below:\n",
    "\n",
    "    1. There exists a path from node i to node j for all nodes i,j in the directed\n",
    "graph. Recall, with this property the jump to an arbitrary node in PageRank\n",
    "is not required, so that you can set q = 1 (refer lecture slides).\n",
    "\n",
    "    2. HITS authority ranking and PageRank ranking of the graph nodes are different.\n",
    "\n",
    "2. Give intuition/methodology on how you constructed such a directed graph with\n",
    "the properties described in (a).\n",
    "\n",
    "3. Are there specific graph structures with arbitrarily large instances where PageRank\n",
    "ranking and HITS authority ranking are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Exercise 4: Hub and Authority\n",
    "\n",
    "In the last exercise, we implement the (iterative) HITS algorithm to calculate the authority and hub scores for this graph.\n",
    "\n",
    "\n",
    "### Goal:\n",
    "1. Implementing HITS algorithm.\n",
    "2. Identifying the best authority and hub nodes for a small graph (part `a`) as well as the `ca-GrQc.txt` dataset (part `b`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### a)\n",
    "\n",
    "Let the adjacency matrix for a graph of four vertices ($n_1$ to $n_4$) be\n",
    "as follows:\n",
    "\n",
    "$\n",
    "A =\n",
    "  \\begin{bmatrix}\n",
    "\t0 & 1 & 1 & 1  \\\\\n",
    "\t0 & 0 & 1 & 1 \\\\\n",
    "\t1 & 0 & 0 & 1 \\\\\n",
    "\t0 & 0 & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "\n",
    "Calculate the authority and hub scores for this graph using the\n",
    "HITS algorithm with k = 6, and identify the best authority and\n",
    "hub nodes. (A non-zero element $A_{ij}$ indicates an edge from $i$ to $j$.)\n",
    "\n",
    "### b)\n",
    "Apply the HITS algorithm to the `ca-GrQc.txt` dataset (the same dataset as for the `Exercise 2`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** We follow the slide \"HITS algorithm\" in the lecture. **Denote $x$ as authority vector and $y$ as hub vector**. You can use matrix multiplication for the update steps in the slide \"Convergence of HITS\". Note that rows of adjacency matrix is from-vertex and columns of adjacency matrix is to-vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can implement your code following this template.\n",
    "def hits_iterative(A, k=10):\n",
    "    N = A.shape[0]\n",
    "    x0, y0 = 1 / (N**0.5) * np.ones(N), 1 / (N**0.5) * np.ones(N)\n",
    "    xprev, yprev = x0, y0\n",
    "    \n",
    "    # For advanced exercise: define a convergence condition instead of k iterations\n",
    "    for l in range(0,k):\n",
    "        y = np.matmul(A, xprev)\n",
    "        x = np.matmul(np.transpose(A), np.transpose(y.flatten()))\n",
    "        xprev = x / np.linalg.norm(x,2)\n",
    "        yprev = y / np.linalg.norm(y,2)\n",
    "        \n",
    "    return xprev, yprev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part `a` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result using iterative method:\n",
      " Authoriy vector x=[[0.1684631 ]\n",
      " [0.27256745]\n",
      " [0.49800689]\n",
      " [0.80580165]]\n",
      " Hub vector y=[[0.65548852]\n",
      " [0.54215191]\n",
      " [0.40513139]\n",
      " [0.33507412]]\n"
     ]
    }
   ],
   "source": [
    "A= np.matrix([[0,1,1,1], [0,0,1,1], [1,0,0,1], [0,0,0,1]]) # your code here\n",
    "\n",
    "x, y = hits_iterative(A, k=6)\n",
    "print(\"Result using iterative method:\\n Authoriy vector x={0}\\n Hub vector y={1}\".format(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part `b` dataset\n",
    "You can reuse the link matrix $L$ (from Exercise 2) to compute the adjacency matrix $A$ of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A = adj # your code here\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run HITS algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result using iterative method:\n",
      " Authoriy vector x=[3.48948725e-005 1.45965100e-005 6.68130767e-006 ... 2.85093646e-273\n",
      " 2.85093646e-273 2.85093646e-273]\n",
      " Hub vector y=[3.48948725e-005 1.45965100e-005 6.68130767e-006 ... 6.50251027e-272\n",
      " 6.50251027e-272 6.50251027e-272]\n"
     ]
    }
   ],
   "source": [
    "x, y = hits_iterative(A, 100)\n",
    "print(\"Result using iterative method:\\n Authoriy vector x={0}\\n Hub vector y={1}\".format(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authority and the hub rankings are the same because we did the analysis for an undirected graph. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "0342ec1e726abc401ff31a289c96ceabd6ba6f02cfbaf74ce2cfcd829be9f0a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
